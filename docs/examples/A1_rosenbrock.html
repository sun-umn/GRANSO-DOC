
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Rosenbrock &#8212; NCVX PyGRANSO Documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Eigenvalue Optimization" href="A2_eigenval_opt.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/PyGRANSO_logo_banner.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NCVX PyGRANSO Documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../install.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../settings/index.html">
   Settings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/standard_parameters.html">
     Standard Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/searching_direction.html">
     Searching Direction Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/steering_strategy.html">
     Steering Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/qp_parameters.html">
     QP Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/line_search.html">
     Line Search Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/new_para.html">
     PyGRANSO New Options
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Rosenbrock
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="A2_eigenval_opt.html">
     Eigenvalue Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="A3_dict_learning.html">
     Dictionary Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="B1_nonlinear_feasiblity.html">
     Nonlinear Feasibility Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="B2_sphere_manifold.html">
     Sphere Manifold
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="B3_trace_optimization.html">
     Trace Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="C1_robustPCA.html">
     Robust PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="C2_generalizedLASSO.html">
     Generalized LASSO
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="C3_logistic_regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="D1_LeNet5.html">
     LeNet5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="D2_perceptual_attack.html">
     Perceptual Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="D3_orthogonal_rnn.html">
     Orthogonal RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../highlight/index.html">
   Highlights
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../highlight/SDM23.html">
     Deep Learning with Nontrivial Constraints
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mistakes.html">
   Tips
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../citation.html">
   Citing PyGRANSO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://groups.google.com/a/umn.edu/g/ncvx">
   NCVX PyGRANSO Forum
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/examples/A1_rosenbrock.ipynb.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/sun-umn/PyGRANSO"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/sun-umn/PyGRANSO/issues/new?title=Issue%20on%20page%20%2Fexamples/A1_rosenbrock.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Problem-Description">
   Problem Description
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Modules-Importing">
   Modules Importing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Function-Set-Up">
   Function Set-Up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#User-Options">
   User Options
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Main-Algorithm">
   Main Algorithm
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#PyGRANSO-Restarting">
   PyGRANSO Restarting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Results-Logs">
   Results Logs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#LFBGS-Restarting">
   LFBGS Restarting
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Rosenbrock">
<h1>Rosenbrock<a class="headerlink" href="#Rosenbrock" title="Permalink to this headline">¶</a></h1>
<p>Minimize 2-variable nonsmooth Rosenbrock function, subject to a simple bound constraint. Taken from: <a class="reference external" href="http://www.timmitchell.com/software/GRANSO/">GRANSO</a> demo examples 1, 2, &amp; 3</p>
<div class="section" id="Problem-Description">
<h2>Problem Description<a class="headerlink" href="#Problem-Description" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\min_{x_1,x_2} w|x_1^2-x_2|+(1-x_1)^2,\]</div>
<div class="math notranslate nohighlight">
\[\text{s.t. }c_1(x_1,x_2) = \sqrt{2}x_1-1 \leq 0, c_(x_1,x_2)=2x_2-1\leq0,\]</div>
<p>where <span class="math notranslate nohighlight">\(w\)</span> is a constant (e.g., <span class="math notranslate nohighlight">\(w=8\)</span>)</p>
</div>
<div class="section" id="Modules-Importing">
<h2>Modules Importing<a class="headerlink" href="#Modules-Importing" title="Permalink to this headline">¶</a></h2>
<p>Import all necessary modules and add PyGRANSO src folder to system path.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pygranso.pygranso</span> <span class="kn">import</span> <span class="n">pygranso</span>
<span class="kn">from</span> <span class="nn">pygranso.pygransoStruct</span> <span class="kn">import</span> <span class="n">pygransoStruct</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Function-Set-Up">
<h2>Function Set-Up<a class="headerlink" href="#Function-Set-Up" title="Permalink to this headline">¶</a></h2>
<p>Encode the optimization variables, and objective and constraint functions.</p>
<p>Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="c1"># variables and corresponding dimensions.</span>
<span class="n">var_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]}</span>

<span class="k">def</span> <span class="nf">comb_fn</span><span class="p">(</span><span class="n">X_struct</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x2</span>

    <span class="c1"># objective function</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># inequality constraint, matrix form</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">x1</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x2</span><span class="o">-</span><span class="mi">1</span>

    <span class="c1"># equality constraint</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">f</span><span class="p">,</span><span class="n">ci</span><span class="p">,</span><span class="n">ce</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="User-Options">
<h2>User Options<a class="headerlink" href="#User-Options" title="Permalink to this headline">¶</a></h2>
<p>Specify user-defined options for PyGRANSO</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="c1"># option for switching QP solver. We only have osqp as the only qp solver in current version. Default is osqp</span>
<span class="c1"># opts.QPsolver = &#39;osqp&#39;</span>

<span class="c1"># set an intial point</span>
<span class="c1"># All the user-provided data (vector/matrix/tensor) must be in torch tensor format.</span>
<span class="c1"># As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.</span>
<span class="c1"># Also, please make sure the device of provided torch tensor is the same as opts.torch_device.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Main-Algorithm">
<h2>Main Algorithm<a class="headerlink" href="#Main-Algorithm" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Wall Time: </span><span class="si">{}</span><span class="s2">s&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.2.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  1.41421356237 ║  0.00000000000 ║ 1.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.579471   ║
   1 ║ 1.000000 │  0.70773811042 ║  0.70773811042 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 10.07366   ║
   2 ║ 1.000000 │  0.25401310554 ║  0.25401310554 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.198885   ║
   3 ║ 1.000000 │  0.21478744238 ║  0.21478744238 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.135710   ║
   4 ║ 1.000000 │  0.21422378595 ║  0.21422378595 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.332997   ║
   5 ║ 1.000000 │  0.15330884270 ║  0.15330884270 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.122691   ║
   6 ║ 1.000000 │  0.14804462353 ║  0.14804462353 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.012623   ║
   7 ║ 1.000000 │  0.10856024489 ║  0.10856024489 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.042111   ║
   8 ║ 1.000000 │  0.10482595154 ║  0.10482595154 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003211   ║
   9 ║ 0.810000 │  0.07758251262 ║  0.09438278485 ║ 0.001132 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.038778   ║
  10 ║ 0.810000 │  0.07197699268 ║  0.08886048479 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012307   ║
  11 ║ 0.810000 │  0.07055904204 ║  0.08710992844 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.003100   ║
  12 ║ 0.810000 │  0.07048871361 ║  0.08702310322 ║ 0.000000 │   -  ║ S  │     7 │ 0.046875 ║     1 │ 0.003061   ║
  13 ║ 0.810000 │  0.07020995506 ║  0.08667895687 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001026   ║
  14 ║ 0.810000 │  0.06962027906 ║  0.08595096180 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 5.51e-06   ║
  15 ║ 0.810000 │  0.06952233581 ║  0.08581975963 ║ 8.33e-06 │   -  ║ S  │     3 │ 4.000000 ║     2 │ 5.10e-06   ║
  16 ║ 0.729000 │  0.06255153247 ║  0.08579440422 ║ 4.17e-06 │   -  ║ S  │     2 │ 0.500000 ║     3 │ 3.98e-06   ║
  17 ║ 0.729000 │  0.06254666970 ║  0.08579790082 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 7.59e-19   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Optimization results:                                                                                            ║
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08579790082 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578643763 ║ 0.000000 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578643763 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              17                                                                                      ║
Function evaluations:    40                                                                                      ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
Total Wall Time: 0.18392133712768555s
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</div>
<div class="section" id="PyGRANSO-Restarting">
<h2>PyGRANSO Restarting<a class="headerlink" href="#PyGRANSO-Restarting" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong> The following example shows how to set various PyGRANSO options (such as simpler ASCII printing) and how to restart PyGRANSO</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="c1"># By default PyGRANSO will print using extended ASCII characters to &#39;draw&#39; table borders and some color prints.</span>
<span class="c1"># If user wants to create a log txt file of the console output, please set opts.print_ascii = True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># By default, PyGRANSO prints an info message about QP solvers, since</span>
<span class="c1"># PyGRANSO can be used with any QP solver that has a quadprog-compatible</span>
<span class="c1"># interface.  Let&#39;s disable this message since we&#39;ve already seen it</span>
<span class="c1"># hundreds of times and can now recite it from memory.  ;-)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Try a very short run.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>

<span class="c1"># PyGRANSO&#39;s penalty parameter is on the *objective* function, thus</span>
<span class="c1"># higher penalty parameter values favor objective minimization more</span>
<span class="c1"># highly than attaining feasibility.  Let&#39;s set PyGRANSO to start off</span>
<span class="c1"># with a higher initial value of the penalty parameter.  PyGRANSO will</span>
<span class="c1"># automatically tune the penalty parameter to promote progress towards</span>
<span class="c1"># feasibility.  PyGRANSO only adjusts the penalty parameter in a</span>
<span class="c1"># monotonically decreasing fashion.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             |
Version 1.2.0                                                                                                    |
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.770   |
   1 | 34.86784 |  1509.66611872 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6040   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   3 | 12.15767 |  285.452828054 |  22.6935200208 | 9.552604 |   -  | S  |     2 | 2.000000 |     1 | 0.297144   |
   4 | 12.15767 |  264.999595731 |  21.0732808630 | 8.797697 |   -  | S  |     2 | 2.000000 |     1 | 0.603629   |
   5 | 4.239116 |  60.5144787250 |  12.1478493778 | 9.018338 |   -  | S  |     2 | 2.000000 |     1 | 0.111610   |
   6 | 4.239116 |  53.5399399407 |  10.5181947367 | 8.952094 |   -  | S  |     2 | 0.500000 |     1 | 0.164082   |
   7 | 3.815204 |  48.9917031616 |  10.4947962860 | 8.951912 |   -  | S  |     4 | 0.125000 |     1 | 0.033640   |
   8 | 3.815204 |  48.7011303503 |  10.4372013183 | 8.881076 |   -  | S  |     2 | 2.000000 |     1 | 0.018555   |
   9 | 3.815204 |  48.2564717826 |  10.3422772655 | 8.798572 |   -  | S  |     2 | 2.000000 |     1 | 0.057946   |
  10 | 3.815204 |  39.4225027901 |  9.27057783616 | 4.053355 |   -  | S  |     5 | 16.00000 |     1 | 0.001796   |
==================================================================================================================
Optimization results:                                                                                            |
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
==================================================================================================================
   F |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
  MF |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    35                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
<p>Let’s restart PyGRANSO from the last iterate of the previous run</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>
<span class="n">opts</span><span class="o">.</span><span class="n">opt_tol</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="c1"># PREPARE TO RESTART PyGRANSO IN FULL-MEMORY MODE</span>
<span class="c1"># Set the last BFGS inverse Hessian approximation as the initial</span>
<span class="c1"># Hessian for the next run.  Generally this is a good thing to do, and</span>
<span class="c1"># often it is necessary to retain this information when restarting (as</span>
<span class="c1"># on difficult nonsmooth problems, PyGRANSO may not be able to restart</span>
<span class="c1"># without it).  However, your mileage may vary.  In the test, with</span>
<span class="c1"># the above settings, omitting H0 causes PyGRANSO to take an additional</span>
<span class="c1"># 16 iterations to converge on this problem.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">H0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>     <span class="c1"># try running with this commented out</span>

<span class="c1"># When restarting, soln.H_final may fail PyGRANSO&#39;s initial check to</span>
<span class="c1"># assess whether or not the user-provided H0 is positive definite.  If</span>
<span class="c1"># it fails this test, the test may be disabled by setting opts.checkH0</span>
<span class="c1"># to false.</span>
<span class="c1"># opts.checkH0 = False       % Not needed for this example</span>

<span class="c1"># If one desires to restart PyGRANSO as if it had never stopped (e.g.</span>
<span class="c1"># to continue optimization after it hit its maxit limit), then one must</span>
<span class="c1"># also disable scaling the initial BFGS inverse Hessian approximation</span>
<span class="c1"># on the very first iterate.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.2.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 3.815204 │  39.4225027901 ║  9.27057783616 ║ 4.053355 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.161642   ║
   1 ║ 2.503156 │  27.1659262914 ║  9.40498130422 ║ 3.623796 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.052069   ║
   2 ║ 2.252840 │  24.6931839860 ║  9.60278347893 ║ 3.059650 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.121925   ║
   3 ║ 2.027556 │  22.3469956308 ║  9.74369172380 ║ 2.591115 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.107446   ║
   4 ║ 2.027556 │  21.7313246108 ║  9.83432474079 ║ 1.791681 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.249443   ║
   5 ║ 2.027556 │  18.8070548305 ║  9.27572664351 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 1.149786   ║
   6 ║ 2.027556 │  15.5789878011 ║  7.13239951765 ║ 1.117649 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 1.812487   ║
   7 ║ 2.027556 │  5.32456682805 ║  2.62610104757 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.324572   ║
   8 ║ 2.027556 │  5.06514188742 ║  2.49815146400 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.840053   ║
   9 ║ 2.027556 │  4.34855971809 ║  2.14472981556 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.161357   ║
  10 ║ 2.027556 │  4.17458588015 ║  2.05892511204 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.438844   ║
  11 ║ 2.027556 │  3.88777301389 ║  1.91746767656 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.026078   ║
  12 ║ 2.027556 │  3.02755206246 ║  1.49320271480 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.341024   ║
  13 ║ 2.027556 │  2.82661618788 ║  1.39410020980 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.138146   ║
  14 ║ 2.027556 │  2.61942625386 ║  1.29191317368 ║ 0.000000 │   -  ║ S  │     4 │ 3.000000 ║     1 │ 0.271047   ║
  15 ║ 2.027556 │  2.41981099682 ║  1.19346200337 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.022472   ║
  16 ║ 2.027556 │  1.68687275803 ║  0.83197346564 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.273910   ║
  17 ║ 2.027556 │  1.62715982554 ║  0.80252277047 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.038027   ║
  18 ║ 2.027556 │  1.53557783057 ║  0.75735410592 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.015193   ║
  19 ║ 2.027556 │  1.04198868285 ║  0.51391364968 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.094309   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 2.027556 │  0.93149970489 ║  0.45941997346 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.110416   ║
  21 ║ 2.027556 │  0.82149497454 ║  0.40516513040 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.029324   ║
  22 ║ 2.027556 │  0.71807054560 ║  0.35415572251 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.173107   ║
  23 ║ 2.027556 │  0.71364643723 ║  0.35197373175 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012969   ║
  24 ║ 2.027556 │  0.54336780853 ║  0.26799152256 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.049872   ║
  25 ║ 2.027556 │  0.52920946359 ║  0.26100856119 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.090110   ║
  26 ║ 2.027556 │  0.38297864798 ║  0.18888684491 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.078443   ║
  27 ║ 2.027556 │  0.34625417862 ║  0.17077416634 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.148051   ║
  28 ║ 2.027556 │  0.33665070462 ║  0.16603768844 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003684   ║
  29 ║ 2.027556 │  0.26789115070 ║  0.13212515763 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.089877   ║
  30 ║ 2.027556 │  0.25588826429 ║  0.12620527840 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.054336   ║
  31 ║ 2.027556 │  0.19518453283 ║  0.09626591659 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.028392   ║
  32 ║ 2.027556 │  0.19483151740 ║  0.09609180774 ║ 0.000000 │   -  ║ S  │     5 │ 0.062500 ║     1 │ 0.026507   ║
  33 ║ 2.027556 │  0.17882219593 ║  0.08819593616 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.43e-05   ║
  34 ║ 2.027556 │  0.17424853428 ║  0.08592330867 ║ 3.42e-05 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 4.88e-05   ║
  35 ║ 1.077526 │  0.09246135145 ║  0.08580889928 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     2 │ 6.04e-18   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Optimization results:                                                                                            ║
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08580889928 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08580889928 ║ 0.000000 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08580889928 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              35                                                                                      ║
Function evaluations:    77                                                                                      ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</div>
<div class="section" id="Results-Logs">
<h2>Results Logs<a class="headerlink" href="#Results-Logs" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong> opts below shows the importance of using an initial point that is neither near nor on a nonsmooth manifold, that is, the functions (objective and constraints) should be smooth at and <em>about</em> the initial point.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># Set a randomly generated starting point.  In theory, with probability</span>
<span class="c1"># one, a randomly selected point will not be on a nonsmooth manifold.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>   <span class="c1"># randomly generated is okay</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># we&#39;ll use this value of maxit later</span>
<span class="n">opts</span><span class="o">.</span><span class="n">opt_tol</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="c1"># However, (0,0) or (1,1) are on the nonsmooth manifold and if PyGRANSO</span>
<span class="c1"># is started at either of them, it will break down on the first</span>
<span class="c1"># iteration.  This example highlights that it is imperative to start</span>
<span class="c1"># PyGRANSO at a point where the functions are smooth.</span>

<span class="c1"># Uncomment either of the following two lines to try starting PyGRANSO</span>
<span class="c1"># from (0,0) or (1,1), where the functions are not differentiable.</span>

<span class="c1"># opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)     # uncomment this line to try this point</span>
<span class="c1"># opts.x0 = torch.zeros((2,1), device=device, dtype=torch.double)    # uncomment this line to try this point</span>

<span class="c1"># Uncomment the following two lines to try starting PyGRANSO from a</span>
<span class="c1"># uniformly perturbed version of (1,1).  pert_level needs to be at</span>
<span class="c1"># least 1e-3 or so to get consistently reliable optimization quality.</span>

<span class="c1"># pert_level = 1e-3</span>
<span class="c1"># opts.x0 = (torch.ones((2,1)) + pert_level * (torch.randn((2,1)) - 0.5)).to(device=device, dtype=torch.double)</span>
</pre></div>
</div>
</div>
<p>The opts below show how to use opts.halt_log_fn to create a history of iterates</p>
<p>NOTE: NO NEED TO CHANGE ANYTHING BELOW</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># SETUP THE LOGGING FEATURES</span>

<span class="c1"># Set up PyGRANSO&#39;s logging functions; pass opts.maxit to it so that</span>
<span class="c1"># storage can be preallocated for efficiency.</span>

<span class="k">class</span> <span class="nc">HaltLog</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">haltLog</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span>
                <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">):</span>

        <span class="c1"># DON&#39;T CHANGE THIS</span>
        <span class="c1"># increment the index/count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># EXAMPLE:</span>
        <span class="c1"># store history of x iterates in a preallocated cell array</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">tv</span><span class="p">)</span>

        <span class="c1"># keep this false unless you want to implement a custom termination</span>
        <span class="c1"># condition</span>
        <span class="n">halt</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">halt</span>

    <span class="c1"># Once PyGRANSO has run, you may call this function to get retreive all</span>
    <span class="c1"># the logging data stored in the shared variables, which is populated</span>
    <span class="c1"># by haltLog being called on every iteration of PyGRANSO.</span>
    <span class="k">def</span> <span class="nf">getLog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># EXAMPLE</span>
        <span class="c1"># return x_iterates, trimmed to correct size</span>
        <span class="n">log</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
        <span class="n">log</span><span class="o">.</span><span class="n">x</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">f</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">tv</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">log</span>

    <span class="k">def</span> <span class="nf">makeHaltLogFunctions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">maxit</span><span class="p">):</span>
        <span class="c1"># don&#39;t change these lambda functions</span>
        <span class="n">halt_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">haltLog</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">)</span>

        <span class="n">get_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">getLog</span><span class="p">()</span>

        <span class="c1"># Make your shared variables here to store PyGRANSO history data</span>
        <span class="c1"># EXAMPLE - store history of iterates x_0,x_1,...,x_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span>       <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span>  <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span>           <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span>          <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Only modify the body of logIterate(), not its name or arguments.</span>
        <span class="c1"># Store whatever data you wish from the current PyGRANSO iteration info,</span>
        <span class="c1"># given by the input arguments, into shared variables of</span>
        <span class="c1"># makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO</span>
        <span class="c1"># has been terminated.</span>
        <span class="c1">#</span>
        <span class="c1"># DESCRIPTION OF INPUT ARGUMENTS</span>
        <span class="c1">#   iter                current iteration number</span>
        <span class="c1">#   x                   current iterate x</span>
        <span class="c1">#   penaltyfn_parts     struct containing the following</span>
        <span class="c1">#       OBJECTIVE AND CONSTRAINTS VALUES</span>
        <span class="c1">#       .f              objective value at x</span>
        <span class="c1">#       .f_grad         objective gradient at x</span>
        <span class="c1">#       .ci             inequality constraint at x</span>
        <span class="c1">#       .ci_grad        inequality gradient at x</span>
        <span class="c1">#       .ce             equality constraint at x</span>
        <span class="c1">#       .ce_grad        equality gradient at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)</span>
        <span class="c1">#       .tvi            total violation of inequality constraints at x</span>
        <span class="c1">#       .tve            total violation of equality constraints at x</span>
        <span class="c1">#       .tv             total violation of all constraints at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)</span>
        <span class="c1">#       .tvi_l1         total violation of inequality constraints at x</span>
        <span class="c1">#       .tvi_l1_grad    its gradient</span>
        <span class="c1">#       .tve_l1         total violation of equality constraints at x</span>
        <span class="c1">#       .tve_l1_grad    its gradient</span>
        <span class="c1">#       .tv_l1          total violation of all constraints at x</span>
        <span class="c1">#       .tv_l1_grad     its gradient</span>
        <span class="c1">#       PENALTY FUNCTION VALUES</span>
        <span class="c1">#       .p              penalty function value at x</span>
        <span class="c1">#       .p_grad         penalty function gradient at x</span>
        <span class="c1">#       .mu             current value of the penalty parameter</span>
        <span class="c1">#       .feasible_to_tol logical indicating whether x is feasible</span>
        <span class="c1">#   d                   search direction</span>
        <span class="c1">#   get_BFGS_state_fn   function handle to get the (L)BFGS state data</span>
        <span class="c1">#                       FULL MEMORY:</span>
        <span class="c1">#                       - returns BFGS inverse Hessian approximation</span>
        <span class="c1">#                       LIMITED MEMORY:</span>
        <span class="c1">#                       - returns a struct with current L-BFGS state:</span>
        <span class="c1">#                           .S          matrix of the BFGS s vectors</span>
        <span class="c1">#                           .Y          matrix of the BFGS y vectors</span>
        <span class="c1">#                           .rho        row vector of the 1/sty values</span>
        <span class="c1">#                           .gamma      H0 scaling factor</span>
        <span class="c1">#   H_regularized       regularized version of H</span>
        <span class="c1">#                       [] if no regularization was applied to H</span>
        <span class="c1">#   fn_evals            number of function evaluations incurred during</span>
        <span class="c1">#                       this iteration</span>
        <span class="c1">#   alpha               size of accepted size</span>
        <span class="c1">#   n_gradients         number of previous gradients used for computing</span>
        <span class="c1">#                       the termination QP</span>
        <span class="c1">#   stat_vec            stationarity measure vector</span>
        <span class="c1">#   stat_val            approximate value of stationarity:</span>
        <span class="c1">#                           norm(stat_vec)</span>
        <span class="c1">#                       gradients (result of termination QP)</span>
        <span class="c1">#   fallback_level      number of strategy needed for a successful step</span>
        <span class="c1">#                       to be taken.  See bfgssqpOptionsAdvanced.</span>
        <span class="c1">#</span>
        <span class="c1"># OUTPUT ARGUMENT</span>
        <span class="c1">#   halt                set this to true if you wish optimization to</span>
        <span class="c1">#                       be halted at the current iterate.  This can be</span>
        <span class="c1">#                       used to create a custom termination condition,</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span>

<span class="n">mHLF_obj</span> <span class="o">=</span> <span class="n">HaltLog</span><span class="p">()</span>
<span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span> <span class="o">=</span> <span class="n">mHLF_obj</span><span class="o">.</span><span class="n">makeHaltLogFunctions</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">maxit</span><span class="p">)</span>

<span class="c1">#  Set PyGRANSO&#39;s logging function in opts</span>
<span class="n">opts</span><span class="o">.</span><span class="n">halt_log_fn</span> <span class="o">=</span> <span class="n">halt_log_fn</span>

<span class="c1"># Main algorithm with logging enabled.</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>

<span class="c1"># GET THE HISTORY OF ITERATES</span>
<span class="c1"># Even if an error is thrown, the log generated until the error can be</span>
<span class="c1"># obtained by calling get_log_fn()</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">get_log_fn</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.2.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  16.4067374414 ║  16.4067374414 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 16.89371   ║
   1 ║ 1.000000 │  12.1088353467 ║  11.5118588213 ║ 0.596977 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 19.28340   ║
   2 ║ 1.000000 │  1.11708224486 ║  1.11708224486 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.478277   ║
   3 ║ 1.000000 │  0.55748343428 ║  0.55748343428 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.825482   ║
   4 ║ 1.000000 │  0.54324826834 ║  0.54324826834 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.072797   ║
   5 ║ 1.000000 │  0.43272406722 ║  0.43272406722 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.029511   ║
   6 ║ 1.000000 │  0.39143728403 ║  0.39143728403 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.165019   ║
   7 ║ 1.000000 │  0.33585127390 ║  0.33585127390 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.111788   ║
   8 ║ 1.000000 │  0.27769332848 ║  0.27769332848 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016351   ║
   9 ║ 1.000000 │  0.27206257507 ║  0.27206257507 ║ 0.000000 │   -  ║ S  │     6 │ 0.093750 ║     1 │ 0.185187   ║
  10 ║ 1.000000 │  0.25369049840 ║  0.25369049840 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018059   ║
  11 ║ 1.000000 │  0.24095795441 ║  0.24095795441 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002996   ║
  12 ║ 1.000000 │  0.22956867248 ║  0.22956867248 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.014434   ║
  13 ║ 1.000000 │  0.16940732170 ║  0.16940732170 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.080774   ║
  14 ║ 1.000000 │  0.14128118763 ║  0.14128118763 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.100849   ║
  15 ║ 1.000000 │  0.13056475076 ║  0.13056475076 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.005391   ║
  16 ║ 1.000000 │  0.12030008103 ║  0.12030008103 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.035053   ║
  17 ║ 1.000000 │  0.09388862233 ║  0.09388862233 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001793   ║
  18 ║ 1.000000 │  0.08668315753 ║  0.08668315753 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.001835   ║
  19 ║ 1.000000 │  0.08658279210 ║  0.08658279210 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.001426   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 1.000000 │  0.08597722224 ║  0.08597722224 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.76e-05   ║
  21 ║ 0.900000 │  0.07729405862 ║  0.08588228736 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     2 │ 1.39e-05   ║
  22 ║ 0.900000 │  0.07725449555 ║  0.08583832839 ║ 0.000000 │   -  ║ S  │     5 │ 0.062500 ║     1 │ 1.42e-04   ║
  23 ║ 0.900000 │  0.07725013449 ║  0.08583348277 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     2 │ 5.96e-05   ║
  24 ║ 0.900000 │  0.07723808110 ║  0.08580155461 ║ 9.62e-06 │   -  ║ S  │     4 │ 1.250000 ║     2 │ 7.31e-06   ║
  25 ║ 0.900000 │  0.07721211695 ║  0.08579124105 ║ 6.63e-13 │   -  ║ S  │     1 │ 1.000000 ║     3 │ 4.06e-13   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Optimization results:                                                                                            ║
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08579124105 ║ 6.63e-13 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08579124105 ║ 6.63e-13 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08580793766 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              25                                                                                      ║
Function evaluations:    60                                                                                      ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[16.406737441369938, 11.51185882133243, 1.117082244864862]
[tensor([[-0.8448],
        [-0.9117]], dtype=torch.float64), tensor([[ 1.1292],
        [-0.1617]], dtype=torch.float64), tensor([[0.3125],
        [0.0171]], dtype=torch.float64)]
</pre></div></div>
</div>
</div>
<div class="section" id="LFBGS-Restarting">
<h2>LFBGS Restarting<a class="headerlink" href="#LFBGS-Restarting" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong></p>
<p>(Note that this example problem only has two variables!)</p>
<p>If PyGRANSO runs in limited-memory mode, that is, if opts.limited_mem_size &gt; 0, then PyGRANSO’s restart procedure is slightly different from the BFGS restarting, as soln.H_final will instead contain the most current L-BFGS state, not a full inverse Hessian approximation.</p>
<p>Instead the BFGS standard procedure, users should do the following: 1) If you set a specific H0, you will need to set opts.H0 to whatever you used previously. By default, PyGRANSO uses the identity for H0.</p>
<ol class="arabic simple" start="2">
<li><p>Warm-start PyGRANSO with the most recent L-BFGS data by setting: opts.limited_mem_warm_start = soln.H_final;</p></li>
</ol>
<p>NOTE: how to set opts.scaleH0 so that PyGRANSO will be restarted as if it had never terminated depends on the previously used values of opts.scaleH0 and opts.limited_mem_fixed_scaling.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>


<span class="c1"># By default, PyGRANSO uses full-memory BFGS updating.  For nonsmooth</span>
<span class="c1"># problems, full-memory BFGS is generally recommended.  However, if</span>
<span class="c1"># this is not feasible, one may optionally enable limited-memory BFGS</span>
<span class="c1"># updating by setting opts.limited_mem_size to a positive integer</span>
<span class="c1"># (significantly) less than the number of variables.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             |
Version 1.2.0                                                                                                    |
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
Limited-memory mode enabled with size = 1.                                                                       |
NOTE: limited-memory mode is generally NOT                                                                       |
recommended for nonsmooth problems.                                                                              |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.770   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   4 | 12.15767 |  262.610250639 |  20.8774186596 | 8.789579 |   -  | S  |     2 | 2.000000 |     1 | 0.604009   |
   6 | 4.239116 |  57.9458175917 |  11.5708792009 | 8.895520 |   -  | S  |     3 | 0.750000 |     1 | 0.165224   |
   8 | 1.642320 |  26.2056730861 |  10.5532019880 | 8.873935 |   -  | S  |     1 | 1.000000 |     1 | 0.027766   |
  10 | 1.642320 |  25.9163909350 |  10.4174724535 | 8.807564 |   -  | S  |     2 | 2.000000 |     1 | 0.021455   |
==================================================================================================================
Optimization results:                                                                                            |
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
==================================================================================================================
   F |          |                |  10.4174724535 | 8.807564 |   -  |    |       |          |       |            |
  MF |          |                |  75.6886238113 | 8.192103 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    29                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Restart</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_warm_start</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># In contrast to full-memory BFGS updating, limited-memory BFGS</span>
<span class="c1"># permits that H0 can be scaled on every iteration.  By default,</span>
<span class="c1"># PyGRANSO will reuse the scaling parameter that is calculated on the</span>
<span class="c1"># very first iteration for all subsequent iterations as well.  Set</span>
<span class="c1"># this option to false to force PyGRANSO to calculate a new scaling</span>
<span class="c1"># parameter on every iteration.  Note that opts.scaleH0 has no effect</span>
<span class="c1"># when opts.limited_mem_fixed_scaling is set to true.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_fixed_scaling</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.2.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
<span class="ansi-yellow-fg">Limited-memory mode enabled with size = 1.                                                                      </span> ║
<span class="ansi-yellow-fg">NOTE: limited-memory mode is generally NOT                                                                      </span> ║
<span class="ansi-yellow-fg">recommended for nonsmooth problems.                                                                             </span> ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.642320 │  25.9163909350 ║  10.4174724535 ║ 8.807564 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.142170   ║
   2 ║ 1.642320 │  13.8167164344 ║  6.50516654793 ║ 3.133149 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.838176   ║
   4 ║ 1.642320 │  6.43976368442 ║  3.92113741712 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 3.895256   ║
   6 ║ 1.642320 │  4.81165411491 ║  2.92979027070 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.052493   ║
   8 ║ 1.642320 │  4.63155845135 ║  2.82013099132 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.017665   ║
  10 ║ 1.642320 │  4.03639569243 ║  2.45773959349 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.013749   ║
  12 ║ 1.642320 │  3.00639292821 ║  1.83057645887 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.028975   ║
  14 ║ 1.642320 │  2.28891992127 ║  1.39371100989 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.048897   ║
  16 ║ 1.642320 │  1.95780587454 ║  1.19209745051 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.265478   ║
  18 ║ 1.642320 │  1.49471266813 ║  0.91012249177 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.084726   ║
  20 ║ 1.642320 │  1.34989358124 ║  0.82194292989 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.216509   ║
  22 ║ 1.642320 │  1.13057014213 ║  0.68839806928 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018354   ║
  24 ║ 1.642320 │  1.00727210829 ║  0.61332256067 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.009416   ║
  26 ║ 1.642320 │  0.91876697706 ║  0.55943226303 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012977   ║
  28 ║ 1.642320 │  0.79484835473 ║  0.48397888143 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.096405   ║
  30 ║ 1.642320 │  0.65714700682 ║  0.40013327247 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.142885   ║
  32 ║ 1.642320 │  0.57064376781 ║  0.34746191622 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.005519   ║
  34 ║ 1.642320 │  0.50072121946 ║  0.30488645320 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.002562   ║
  36 ║ 1.642320 │  0.46398321205 ║  0.28251687839 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.010241   ║
  38 ║ 1.642320 │  0.38322497032 ║  0.23334362003 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.145492   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 1.642320 │  0.31487530037 ║  0.19172587420 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.006704   ║
  42 ║ 1.642320 │  0.30050834308 ║  0.18297791129 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.007435   ║
  44 ║ 1.642320 │  0.26424400929 ║  0.16089675380 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.795419   ║
  46 ║ 1.642320 │  0.20338505133 ║  0.12384006214 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004990   ║
  48 ║ 1.642320 │  0.17520417328 ║  0.10668087731 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.003565   ║
  50 ║ 1.077526 │  0.10049441692 ║  0.08991368997 ║ 0.002780 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 0.033750   ║
  52 ║ 1.077526 │  0.09397044638 ║  0.08720941715 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 2.31e-04   ║
  54 ║ 1.077526 │  0.09254093483 ║  0.08588275676 ║ 0.000000 │   -  ║ S  │     5 │ 0.062500 ║     2 │ 2.09e-04   ║
  56 ║ 1.077526 │  0.09244295357 ║  0.08579182510 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     2 │ 1.78e-06   ║
  58 ║ 1.077526 │  0.09243954005 ║  0.08578865717 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 6.93e-15   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Optimization results:                                                                                            ║
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578865717 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578865717 ║ 0.000000 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578865717 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              58                                                                                      ║
Function evaluations:    127                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
</div>
</div>


              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="index.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Examples</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="A2_eigenval_opt.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Eigenvalue Optimization</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Buyun Liang<br/>
        
            &copy; Copyright 2021-2022, Buyun Liang.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>