{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "Train Orthogonal RNN for MNIST classification based on [this Paper](https://arxiv.org/pdf/1901.08428.pdf)\n",
    "\n",
    "NOTE: this example is still under development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c154",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96269c7",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$h_t=\\tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_hh)$$\n",
    "\n",
    "where $h_{t}$ is the hidden state at time $t$, and $h_{t-1}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $o$. \n",
    "\n",
    "For each layer, we have the orthogonal constraint:\n",
    "$$ W_{hh}^T W_{hh} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ed32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/PyGRANSO')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct \n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pygranso.private.getObjGrad import getObjGradDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4842e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buyun/anaconda3/envs/cuosqp_pygranso/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/PyGRANSO/examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ") \n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                        batch_size=100, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb360e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    ce.c1 = A.T @ A - torch.eye(hidden_size).to(device=device, dtype=double_precision)\n",
    "    # ce.c2 = torch.det(A) - 1\n",
    "\n",
    "    # ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model,inputs,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 3e-4\n",
    "opts.viol_eq_tol = 3e-4\n",
    "opts.maxit = 150\n",
    "# opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 10\n",
    "# opts.print_ascii = True\n",
    "# opts.limited_mem_size = 100\n",
    "opts.double_precision = True\n",
    "\n",
    "opts.mu0 = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ba30a",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711f0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 10.00%\n"
     ]
    }
   ],
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632976b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2110                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :    900                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 200.0000 │  521.858725680 ║  2.28955713337 ║   -  │ 0.746091 ║ -  │     1 │ 0.000000 ║     1 │ 22.68972   ║ \n",
      "  10 ║ 62.76212 │  128.098797617 ║  1.73642166416 ║   -  │ 0.957309 ║ S  │     1 │ 1.000000 ║     1 │ 1.225705   ║ \n",
      "  20 ║ 41.17823 │  50.8284833052 ║  1.06189375932 ║   -  │ 1.568086 ║ S  │     1 │ 1.000000 ║     1 │ 0.864339   ║ \n",
      "  30 ║ 27.01703 │  20.8374358771 ║  0.65467158735 ║   -  │ 1.286537 ║ S  │     1 │ 1.000000 ║     1 │ 0.340082   ║ \n",
      "  40 ║ 21.88380 │  10.3384384935 ║  0.38950779214 ║   -  │ 0.627510 ║ S  │     2 │ 0.500000 ║     1 │ 1.333055   ║ \n",
      "  50 ║ 15.95329 │  4.70122280552 ║  0.25233410359 ║   -  │ 0.241137 ║ S  │     1 │ 1.000000 ║     1 │ 0.715793   ║ \n",
      "  60 ║ 3.649601 │  0.73125619485 ║  0.16914007692 ║   -  │ 0.001355 ║ S  │     1 │ 1.000000 ║     1 │ 0.310019   ║ \n",
      "  70 ║ 2.394503 │  0.32977304232 ║  0.12641808772 ║   -  │ 1.86e-04 ║ S  │     1 │ 1.000000 ║     1 │ 0.267671   ║ \n",
      "  80 ║ 0.751420 │  0.08588708751 ║  0.10989096115 ║   -  │ 5.43e-05 ║ S  │     1 │ 1.000000 ║     1 │ 0.026373   ║ \n",
      "  90 ║ 0.028668 │  0.00476881762 ║  0.10632401897 ║   -  │ 5.62e-05 ║ S  │     1 │ 1.000000 ║     1 │ 0.001171   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.10599965581 ║   -  │ 4.89e-05 ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.10528524892 ║   -  │ 1.41e-04 ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.10851492951 ║   -  │ 1.34e-05 ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              93                                                                                      ║ \n",
      "Function evaluations:    136                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 160.9356348514557s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bff5fd",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d846f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 99.00%\n"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8231c34",
   "metadata": {},
   "source": [
    "## PyGRANSO Restarting\n",
    "\n",
    "**(Optional)** The following example shows how to use partial auto-differentiation feature (with user provided gradients) to accelerate pygranso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd25b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial AD\n",
    "def user_fn(model,inputs,labels):\n",
    "    # objective function\n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # get f_grad by AD\n",
    "    n = getNvarTorch(model.parameters())\n",
    "    f_grad = getObjGradDL(nvar=n,model=model,f=f, torch_device=device, double_precision=True)\n",
    "    f = f.detach().item()\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "    ci_grad = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    ce = A.T @ A - torch.eye(hidden_size).to(device=device, dtype=double_precision)\n",
    "    ce = ce.detach()\n",
    "    nconstr = hidden_size*hidden_size\n",
    "    ce = torch.reshape(ce,(nconstr,1))\n",
    "    ce_grad = torch.zeros((n,nconstr)).to(device=device, dtype=double_precision)\n",
    "    M = torch.zeros((nconstr,nconstr)).to(device=device, dtype=double_precision)\n",
    "\n",
    "    for i in range(hidden_size):\n",
    "        for j in range(hidden_size):\n",
    "            J_ij = torch.zeros((hidden_size,hidden_size)).to(device=device, dtype=double_precision)\n",
    "            J_ij[i,j] = 1\n",
    "            tmp = A.T@J_ij + J_ij.T@A\n",
    "            M[hidden_size*i+j,:] = tmp.reshape((1,hidden_size*hidden_size))\n",
    "\n",
    "    ce_grad[input_size*hidden_size:input_size*hidden_size+ hidden_size*(hidden_size),:] = M\n",
    "    ce_grad = ce_grad.detach()\n",
    "\n",
    "    return [f,f_grad,ci,ci_grad,ce,ce_grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf5426",
   "metadata": {},
   "source": [
    "**Important:** set *opts.globalAD = False* to disable global auto-differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9d8f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 10.00%\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2110                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :    900                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 200.0000 │  521.858725680 ║  2.28955713337 ║   -  │ 0.746091 ║ -  │     1 │ 0.000000 ║     1 │ 22.68972   ║ \n",
      "  10 ║ 62.76212 │  128.098797617 ║  1.73642166416 ║   -  │ 0.957309 ║ S  │     1 │ 1.000000 ║     1 │ 1.225705   ║ \n",
      "  20 ║ 41.17823 │  50.8284833052 ║  1.06189375932 ║   -  │ 1.568086 ║ S  │     1 │ 1.000000 ║     1 │ 0.864339   ║ \n",
      "  30 ║ 27.01703 │  20.8374358771 ║  0.65467158735 ║   -  │ 1.286537 ║ S  │     1 │ 1.000000 ║     1 │ 0.340082   ║ \n",
      "  40 ║ 21.88380 │  10.3384384935 ║  0.38950779214 ║   -  │ 0.627510 ║ S  │     2 │ 0.500000 ║     1 │ 1.333055   ║ \n",
      "  50 ║ 15.95329 │  4.70122280552 ║  0.25233410359 ║   -  │ 0.241137 ║ S  │     1 │ 1.000000 ║     1 │ 0.715793   ║ \n",
      "  60 ║ 3.649601 │  0.73125619485 ║  0.16914007692 ║   -  │ 0.001355 ║ S  │     1 │ 1.000000 ║     1 │ 0.310019   ║ \n",
      "  70 ║ 2.394503 │  0.32977304232 ║  0.12641808772 ║   -  │ 1.86e-04 ║ S  │     1 │ 1.000000 ║     1 │ 0.267671   ║ \n",
      "  80 ║ 0.751420 │  0.08588708751 ║  0.10989096115 ║   -  │ 5.43e-05 ║ S  │     1 │ 1.000000 ║     1 │ 0.026373   ║ \n",
      "  90 ║ 0.028668 │  0.00476881762 ║  0.10632401897 ║   -  │ 5.62e-05 ║ S  │     1 │ 1.000000 ║     1 │ 0.001171   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.10599965581 ║   -  │ 4.89e-05 ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.10528524892 ║   -  │ 1.41e-04 ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.10851492951 ║   -  │ 1.34e-05 ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              93                                                                                      ║ \n",
      "Function evaluations:    136                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 94.66318130493164s\n",
      "Final acc = 99.00%\n"
     ]
    }
   ],
   "source": [
    "opts.globalAD = False # disable global auto-differentiation\n",
    "\n",
    "# reinitialize model\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "# initial acc\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs)))) \n",
    "\n",
    "# Main Algorithm\n",
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "\n",
    "# Train acc\n",
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
