
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Rosenbrock &#8212; PyGRANSO  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/haiku.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spectral Radius Optimization" href="2.demo_SpectralRadiusOpt.html" />
    <link rel="prev" title="Examples" href="index.html" /> 
  </head><body>
      <div class="header" role="banner"><img class="rightlogo" src="../_static/PyGRANSO_logo1.png" alt="Logo"/><h1 class="heading"><a href="../index.html">
          <span>PyGRANSO  documentation</span></a></h1>
        <h2 class="heading"><span>Rosenbrock</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">Examples</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="2.demo_SpectralRadiusOpt.html">Spectral Radius Optimization</a>&#160;&#160;»
        </p>

      </div>
      <div class="content" role="main">
        
        
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Rosenbrock">
<h1>Rosenbrock<a class="headerlink" href="#Rosenbrock" title="Permalink to this headline">¶</a></h1>
<p>This notebook contains examples of solving optimization problem with 2-variable nonsmooth Rosenbrock objective function, which subject to simple bound constraints.</p>
<p>Reference: Curtis, Frank E., Tim Mitchell, and Michael L. Overton. “A BFGS-SQP method for nonsmooth, nonconvex, constrained optimization and its evaluation using relative minimization profiles.” Optimization Methods and Software 32.1 (2017): 148-181.</p>
<section id="Problem-Definition">
<h2>Problem Definition<a class="headerlink" href="#Problem-Definition" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\min_{x_1,x_2} w|x_1^2-x_2|+(1-x_1)^2,\]</div>
<div class="math notranslate nohighlight">
\[\text{s.t. }c_1(x_1,x_2) = \sqrt{2}x_1-1 \leq 0, c_(x_1,x_2)=2x_2-1\leq0,\]</div>
<p>where <span class="math notranslate nohighlight">\(w\)</span> is a constant (e.g., <span class="math notranslate nohighlight">\(w=8\)</span>)</p>
</section>
<section id="Import-all-necessary-modules-and-add-PyGRANSO-src-folder-to-system-path.">
<h2>Import all necessary modules and add PyGRANSO src folder to system path.<a class="headerlink" href="#Import-all-necessary-modules-and-add-PyGRANSO-src-folder-to-system-path." title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1">## Adding PyGRANSO directories. Should be modified by user</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;/home/buyun/Documents/GitHub/PyGRANSO&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pygranso</span> <span class="kn">import</span> <span class="n">pygranso</span>
<span class="kn">from</span> <span class="nn">pygransoStruct</span> <span class="kn">import</span> <span class="n">Options</span><span class="p">,</span> <span class="n">Data</span><span class="p">,</span> <span class="n">GeneralStruct</span>
</pre></div>
</div>
</div>
</section>
<section id="Spceify-torch-device,-optimization-variables,-and-corresponding-objective-and-constrained-function.">
<h2>Spceify torch device, optimization variables, and corresponding objective and constrained function.<a class="headerlink" href="#Spceify-torch-device,-optimization-variables,-and-corresponding-objective-and-constrained-function." title="Permalink to this headline">¶</a></h2>
<p>Note: please strictly follow the format of evalObjFunction and combinedFunction, which will be used in the PyGRANSO main algortihm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="c1"># variables and corresponding dimensions.</span>
<span class="n">var_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]}</span>


<span class="k">def</span> <span class="nf">evalObjFunction</span><span class="p">(</span><span class="n">X_struct</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x2</span>

    <span class="c1"># enable autodifferentiation</span>
    <span class="n">x1</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x2</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># objective function</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">combinedFunction</span><span class="p">(</span><span class="n">X_struct</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x2</span>
    <span class="c1"># enable autodifferentiation</span>
    <span class="n">x1</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x2</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># objective function</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># inequality constraint, matrix form</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="n">GeneralStruct</span><span class="p">()</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">x1</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x2</span><span class="o">-</span><span class="mi">1</span>

    <span class="c1"># equality constraint</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">f</span><span class="p">,</span><span class="n">ci</span><span class="p">,</span><span class="n">ce</span><span class="p">]</span>

<span class="n">obj_eval_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X_struct</span> <span class="p">:</span> <span class="n">evalObjFunction</span><span class="p">(</span><span class="n">X_struct</span><span class="p">)</span>
<span class="n">comb_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X_struct</span> <span class="p">:</span> <span class="n">combinedFunction</span><span class="p">(</span><span class="n">X_struct</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Specify-user-defined-options-for-PyGRANSO-algorithm">
<h2>Specify user-defined options for PyGRANSO algorithm<a class="headerlink" href="#Specify-user-defined-options-for-PyGRANSO-algorithm" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># option for switching QP solver. We only have osqp as the only qp solver in current version. Default is osqp</span>
<span class="c1"># opts.QPsolver = &#39;osqp&#39;</span>

<span class="c1"># set an intial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Run-main-algorithm">
<h2>Run main algorithm<a class="headerlink" href="#Run-main-algorithm" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Wall Time: </span><span class="si">{}</span><span class="s2">s&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║
Version 1.1.0                                                                                                    ║
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  1.41421356237 ║  0.00000000000 ║ 1.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.579471   ║
   1 ║ 1.000000 │  0.70773811042 ║  0.70773811042 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 10.07366   ║
   2 ║ 1.000000 │  0.25401310554 ║  0.25401310554 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.198885   ║
   3 ║ 1.000000 │  0.21478744238 ║  0.21478744238 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.135710   ║
   4 ║ 1.000000 │  0.21422378595 ║  0.21422378595 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.332997   ║
   5 ║ 1.000000 │  0.15330884270 ║  0.15330884270 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.122526   ║
   6 ║ 1.000000 │  0.14804462353 ║  0.14804462353 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.012623   ║
   7 ║ 1.000000 │  0.10856024489 ║  0.10856024489 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.042111   ║
   8 ║ 1.000000 │  0.10482600240 ║  0.10482593538 ║ 6.70e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003212   ║
   9 ║ 0.590490 │  0.05930348165 ║  0.09776366663 ║ 0.001575 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.028507   ║
  10 ║ 0.590490 │  0.05288121922 ║  0.08955480909 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.013736   ║
  11 ║ 0.590490 │  0.05256976230 ║  0.08902735406 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 0.005027   ║
  12 ║ 0.590490 │  0.05213546649 ║  0.08829187029 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001898   ║
  13 ║ 0.590490 │  0.05097806280 ║  0.08624466915 ║ 5.14e-05 │   -  ║ S  │     4 │ 1.750000 ║     1 │ 2.18e-05   ║
  14 ║ 0.590490 │  0.05079563998 ║  0.08602286233 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 5.10e-05   ║
  15 ║ 0.590490 │  0.05077733823 ║  0.08599186816 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 3.47e-04   ║
  16 ║ 0.590490 │  0.05071543228 ║  0.08588702943 ║ 2.70e-10 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.05e-05   ║
  17 ║ 0.590490 │  0.05067270160 ║  0.08581466510 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 8.76e-06   ║
  18 ║ 0.590490 │  0.05066273369 ║  0.08579778436 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 4.48e-05   ║
  19 ║ 0.590490 │  0.05066184116 ║  0.08579627286 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 2.46e-06   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 0.590490 │  0.05065742201 ║  0.08578809116 ║ 2.85e-07 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 4.06e-06   ║
  21 ║ 0.228768 │  0.01962567651 ║  0.08578802937 ║ 1.27e-07 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    24 │ 1.19e-07 ║     1 │ 4.30e-07   ║
  22 ║ 0.228768 │  0.01962563551 ║  0.08578840563 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.69e-06   ║
  23 ║ 0.228768 │  0.01962558257 ║  0.08578817425 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.76e-07   ║
  24 ║ 0.228768 │  0.01962531715 ║  0.08578701404 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.17e-07   ║
  25 ║ 0.228768 │  0.01962530099 ║  0.08578694338 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 1.12e-07   ║
  26 ║ 0.228768 │  0.01962527238 ║  0.08578681833 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.24e-08   ║
  27 ║ 0.228768 │  0.01962526814 ║  0.08578679978 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.03e-07   ║
  28 ║ 0.228768 │  0.01962525407 ║  0.08578673829 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.23e-07   ║
  29 ║ 0.228768 │  0.01962521414 ║  0.08578643555 ║ 1.94e-08 │   -  ║ S  │     8 │ 4.250000 ║     1 │ 1.85e-07   ║
  30 ║ 0.228768 │  0.01962521395 ║  0.08578643827 ║ 1.94e-08 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    33 │ 2.33e-10 ║     1 │ 2.32e-08   ║
  31 ║ 0.109419 │  0.00938668494 ║  0.08578653377 ║ 9.14e-09 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    27 │ 1.49e-08 ║     1 │ 1.23e-08   ║
  32 ║ 0.109419 │  0.00938667939 ║  0.08578656654 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 9.53e-08   ║
  33 ║ 0.109419 │  0.00938666755 ║  0.08578645832 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 6.77e-09   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578645832 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578632948 ║ 5.69e-07 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578643763 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              33                                                                                      ║
Function evaluations:    155                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
Total Wall Time: 0.4054887294769287s
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</section>
<section id="Advanced-Tutorial:-Restart-PyGRANSO">
<h2>Advanced Tutorial: Restart PyGRANSO<a class="headerlink" href="#Advanced-Tutorial:-Restart-PyGRANSO" title="Permalink to this headline">¶</a></h2>
<p>the following example shows how to set PyGRANSO options and how to restart PyGRASNO</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="c1"># By default PyGRANSO will print using extended ASCII characters to &#39;draw&#39; table borders and some color prints.</span>
<span class="c1"># If user wants to create a log txt file of the console output, please set opts.print_ascii = True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># By default, PyGRANSO prints an info message about QP solvers, since</span>
<span class="c1"># PyGRANSO can be used with any QP solver that has a quadprog-compatible</span>
<span class="c1"># interface.  Let&#39;s disable this message since we&#39;ve already seen it</span>
<span class="c1"># hundreds of times and can now recite it from memory.  ;-)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Try a very short run.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>

<span class="c1"># PyGRANSO&#39;s penalty parameter is on the *objective* function, thus</span>
<span class="c1"># higher penalty parameter values favor objective minimization more</span>
<span class="c1"># highly than attaining feasibility.  Let&#39;s set PyGRANSO to start off</span>
<span class="c1"># with a higher initial value of the penalty parameter.  PyGRANSO will</span>
<span class="c1"># automatically tune the penalty parameter to promote progress towards</span>
<span class="c1"># feasibility.  PyGRANSO only adjusts the penalty parameter in a</span>
<span class="c1"># monotonically decreasing fashion.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    |
Version 1.1.0                                                                                                    |
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   |
   1 | 34.86784 |  1509.66611872 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6038   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   3 | 12.15767 |  285.452828054 |  22.6935200208 | 9.552604 |   -  | S  |     2 | 2.000000 |     1 | 0.297144   |
   4 | 12.15767 |  264.999595731 |  21.0732808630 | 8.797697 |   -  | S  |     2 | 2.000000 |     1 | 0.603629   |
   5 | 4.239116 |  60.5144787250 |  12.1478493778 | 9.018338 |   -  | S  |     2 | 2.000000 |     1 | 0.111610   |
   6 | 4.239116 |  53.5399399407 |  10.5181947367 | 8.952094 |   -  | S  |     2 | 0.500000 |     1 | 0.164082   |
   7 | 3.815204 |  48.9917031616 |  10.4947962860 | 8.951912 |   -  | S  |     4 | 0.125000 |     1 | 0.033640   |
   8 | 3.815204 |  48.7011303503 |  10.4372013183 | 8.881076 |   -  | S  |     2 | 2.000000 |     1 | 0.018555   |
   9 | 3.815204 |  48.2564717826 |  10.3422772655 | 8.798572 |   -  | S  |     2 | 2.000000 |     1 | 0.057946   |
  10 | 3.815204 |  39.4225027901 |  9.27057783616 | 4.053355 |   -  | S  |     5 | 16.00000 |     1 | 0.001796   |
==================================================================================================================
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
Optimization results:                                                                                            |
==================================================================================================================
   F |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
  MF |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    35                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
</section>
<section id="Let’s-restart-PyGRANSO-from-the-last-iterate-of-the-previous-run">
<h2>Let’s restart PyGRANSO from the last iterate of the previous run<a class="headerlink" href="#Let’s-restart-PyGRANSO-from-the-last-iterate-of-the-previous-run" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>

<span class="c1"># PREPARE TO RESTART PyGRANSO IN FULL-MEMORY MODE</span>
<span class="c1"># Set the last BFGS inverse Hessian approximation as the initial</span>
<span class="c1"># Hessian for the next run.  Generally this is a good thing to do, and</span>
<span class="c1"># often it is necessary to retain this information when restarting (as</span>
<span class="c1"># on difficult nonsmooth problems, PyGRANSO may not be able to restart</span>
<span class="c1"># without it).  However, your mileage may vary.  In the test, with</span>
<span class="c1"># the above settings, omitting H0 causes PyGRANSO to take an additional</span>
<span class="c1"># 16 iterations to converge on this problem.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">H0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>     <span class="c1"># try running with this commented out</span>

<span class="c1"># When restarting, soln.H_final may fail PyGRANSO&#39;s initial check to</span>
<span class="c1"># assess whether or not the user-provided H0 is positive definite.  If</span>
<span class="c1"># it fails this test, the test may be disabled by setting opts.checkH0</span>
<span class="c1"># to false.</span>
<span class="c1"># opts.checkH0 = False       % Not needed for this example</span>

<span class="c1"># If one desires to restart PyGRANSO as if it had never stopped (e.g.</span>
<span class="c1"># to continue optimization after it hit its maxit limit), then one must</span>
<span class="c1"># also disable scaling the initial BFGS inverse Hessian approximation</span>
<span class="c1"># on the very first iterate.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║
Version 1.1.0                                                                                                    ║
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 3.815204 │  39.4225027901 ║  9.27057783616 ║ 4.053355 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.161642   ║
   1 ║ 2.503156 │  27.1660390047 ║  9.40556725606 ║ 3.622442 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.052571   ║
   2 ║ 2.252840 │  24.6945188331 ║  9.60502524451 ║ 3.055934 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.123979   ║
   3 ║ 2.027556 │  22.2891608988 ║  9.93655318601 ║ 2.142243 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.327632   ║
   4 ║ 1.642320 │  17.8465531435 ║  10.2828435436 ║ 0.958830 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.398436   ║
   5 ║ 1.642320 │  13.1535812274 ║  8.00914475244 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 1.156057   ║
   6 ║ 1.642320 │  11.4960225301 ║  6.63100607835 ║ 0.605786 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.564293   ║
   7 ║ 1.642320 │  9.66155156754 ║  5.88286670373 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.131552   ║
   8 ║ 1.642320 │  3.18870986097 ║  1.94158825710 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.753043   ║
   9 ║ 1.642320 │  2.87483444697 ║  1.75047120834 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.218398   ║
  10 ║ 1.642320 │  2.41629634681 ║  1.47126982924 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.032178   ║
  11 ║ 1.642320 │  2.04980550368 ║  1.24811552911 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.322751   ║
  12 ║ 1.642320 │  1.73902679857 ║  1.05888404970 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.125771   ║
  13 ║ 1.642320 │  1.51471510327 ║  0.92230186677 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.277844   ║
  14 ║ 1.642320 │  1.49802532849 ║  0.91213955282 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.158059   ║
  15 ║ 1.642320 │  1.29725505218 ║  0.78989161310 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.017869   ║
  16 ║ 1.642320 │  1.20434505672 ║  0.73331921736 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.208412   ║
  17 ║ 1.642320 │  1.17152363532 ║  0.71333443067 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.019253   ║
  18 ║ 1.642320 │  1.06952845537 ║  0.65123011504 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.016138   ║
  19 ║ 1.642320 │  0.76791462636 ║  0.46757907932 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.091388   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 1.642320 │  0.72307014677 ║  0.44027351727 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.128196   ║
  21 ║ 1.642320 │  0.56223115829 ║  0.34233952360 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.028062   ║
  22 ║ 1.642320 │  0.51427157157 ║  0.31313718961 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.180237   ║
  23 ║ 1.642320 │  0.47234390204 ║  0.28760765749 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012233   ║
  24 ║ 1.642320 │  0.29907407550 ║  0.18210459349 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.135493   ║
  25 ║ 1.642320 │  0.28033053790 ║  0.17069175442 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.106414   ║
  26 ║ 1.642320 │  0.22792497313 ║  0.13878228833 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002056   ║
  27 ║ 1.642320 │  0.19023082159 ║  0.11583052252 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.066610   ║
  28 ║ 1.642320 │  0.18174446709 ║  0.11066322697 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.020754   ║
  29 ║ 1.642320 │  0.16131895207 ║  0.09822624091 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.003332   ║
  30 ║ 1.642320 │  0.15235137930 ║  0.09276472811 ║ 1.98e-06 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001245   ║
  31 ║ 0.872796 │  0.07835617758 ║  0.08889145336 ║ 7.72e-04 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 6.28e-04   ║
  32 ║ 0.872796 │  0.07617998776 ║  0.08716642063 ║ 1.01e-04 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.006103   ║
  33 ║ 0.872796 │  0.07555183821 ║  0.08656296240 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.005428   ║
  34 ║ 0.872796 │  0.07541694972 ║  0.08640841490 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 9.26e-04   ║
  35 ║ 0.872796 │  0.07524953459 ║  0.08621660025 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 5.75e-04   ║
  36 ║ 0.872796 │  0.07520488948 ║  0.08583341378 ║ 1.86e-04 │   -  ║ S  │     5 │ 1.125000 ║     1 │ 1.18e-04   ║
  37 ║ 0.872796 │  0.07487895717 ║  0.08579158747 ║ 3.72e-07 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 5.67e-06   ║
  38 ║ 0.872796 │  0.07487840126 ║  0.08579137696 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 5.23e-05   ║
  39 ║ 0.872796 │  0.07487678240 ║  0.08578952217 ║ 0.000000 │   -  ║ S  │     3 │ 0.750000 ║     1 │ 2.40e-05   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 0.872796 │  0.07487455740 ║  0.08578689597 ║ 6.71e-08 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 5.18e-06   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578689597 ║ 6.71e-08 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578655518 ║ 3.09e-08 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578846025 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              40                                                                                      ║
Function evaluations:    137                                                                                     ║
PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy Wolfe conditions at a   ║
feasible point (to tolerances).  This may be an indication that approximate stationarity has been attained.      ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</section>
<section id="Advanced-Tutorial:-Log-Results">
<h2>Advanced Tutorial: Log Results<a class="headerlink" href="#Advanced-Tutorial:-Log-Results" title="Permalink to this headline">¶</a></h2>
<p>opts below shows the importance of using an initial point that is neither near nor on a nonsmooth manifold, that is, the functions (objective and constraints) should be smooth at and <em>about</em> the initial point.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># Set a randomly generated starting point.  In theory, with probability</span>
<span class="c1"># one, a randomly selected point will not be on a nonsmooth manifold.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>   <span class="c1"># randomly generated is okay</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># we&#39;ll use this value of maxit later</span>

<span class="c1"># However, (0,0) or (1,1) are on the nonsmooth manifold and if GRANSO</span>
<span class="c1"># is started at either of them, it will break down on the first</span>
<span class="c1"># iteration.  This example highlights that it is imperative to start</span>
<span class="c1"># GRANSO at a point where the functions are smooth.</span>

<span class="c1"># Uncomment either of the following two lines to try starting GRANSO</span>
<span class="c1"># from (0,0) or (1,1), where the functions are not differentiable.</span>

<span class="c1"># opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)     # uncomment this line to try this point</span>
<span class="c1"># opts.x0 = torch.zeros((2,1), device=device, dtype=torch.double)    # uncomment this line to try this point</span>

<span class="c1"># Uncomment the following two lines to try starting GRANSO from a</span>
<span class="c1"># uniformly perturbed version of (1,1).  pert_level needs to be at</span>
<span class="c1"># least 1e-3 or so to get consistently reliable optimization quality.</span>

<span class="c1"># pert_level = 1e-3</span>
<span class="c1"># opts.x0 = (torch.ones((2,1)) + pert_level * (torch.randn((2,1)) - 0.5)).to(device=device, dtype=torch.double)</span>
</pre></div>
</div>
</div>
<p>The opts below shows how to use opts.halt_log_fn to create a history of iterates</p>
<p>NOTE: NO NEED TO CHANGE ANYTHING BELOW</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># SETUP THE LOGGING FEATURES</span>

<span class="c1"># Set up PyGRANSO&#39;s logging functions; pass opts.maxit to it so that</span>
<span class="c1"># storage can be preallocated for efficiency.</span>

<span class="k">class</span> <span class="nc">HaltLog</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">haltLog</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span>
                <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">):</span>

        <span class="c1"># DON&#39;T CHANGE THIS</span>
        <span class="c1"># increment the index/count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># EXAMPLE:</span>
        <span class="c1"># store history of x iterates in a preallocated cell array</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">tv</span><span class="p">)</span>

        <span class="c1"># keep this false unless you want to implement a custom termination</span>
        <span class="c1"># condition</span>
        <span class="n">halt</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">halt</span>

    <span class="c1"># Once PyGRANSO has run, you may call this function to get retreive all</span>
    <span class="c1"># the logging data stored in the shared variables, which is populated</span>
    <span class="c1"># by haltLog being called on every iteration of PyGRANSO.</span>
    <span class="k">def</span> <span class="nf">getLog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># EXAMPLE</span>
        <span class="c1"># return x_iterates, trimmed to correct size</span>
        <span class="n">log</span> <span class="o">=</span> <span class="n">GeneralStruct</span><span class="p">()</span>
        <span class="n">log</span><span class="o">.</span><span class="n">x</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">f</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">tv</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">log</span>

    <span class="k">def</span> <span class="nf">makeHaltLogFunctions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">maxit</span><span class="p">):</span>
        <span class="c1"># don&#39;t change these lambda functions</span>
        <span class="n">halt_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">haltLog</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">)</span>

        <span class="n">get_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">getLog</span><span class="p">()</span>

        <span class="c1"># Make your shared variables here to store PyGRANSO history data</span>
        <span class="c1"># EXAMPLE - store history of iterates x_0,x_1,...,x_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span>       <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span>  <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span>           <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span>          <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Only modify the body of logIterate(), not its name or arguments.</span>
        <span class="c1"># Store whatever data you wish from the current PyGRANSO iteration info,</span>
        <span class="c1"># given by the input arguments, into shared variables of</span>
        <span class="c1"># makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO</span>
        <span class="c1"># has been terminated.</span>
        <span class="c1">#</span>
        <span class="c1"># DESCRIPTION OF INPUT ARGUMENTS</span>
        <span class="c1">#   iter                current iteration number</span>
        <span class="c1">#   x                   current iterate x</span>
        <span class="c1">#   penaltyfn_parts     struct containing the following</span>
        <span class="c1">#       OBJECTIVE AND CONSTRAINTS VALUES</span>
        <span class="c1">#       .f              objective value at x</span>
        <span class="c1">#       .f_grad         objective gradient at x</span>
        <span class="c1">#       .ci             inequality constraint at x</span>
        <span class="c1">#       .ci_grad        inequality gradient at x</span>
        <span class="c1">#       .ce             equality constraint at x</span>
        <span class="c1">#       .ce_grad        equality gradient at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)</span>
        <span class="c1">#       .tvi            total violation of inequality constraints at x</span>
        <span class="c1">#       .tve            total violation of equality constraints at x</span>
        <span class="c1">#       .tv             total violation of all constraints at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)</span>
        <span class="c1">#       .tvi_l1         total violation of inequality constraints at x</span>
        <span class="c1">#       .tvi_l1_grad    its gradient</span>
        <span class="c1">#       .tve_l1         total violation of equality constraints at x</span>
        <span class="c1">#       .tve_l1_grad    its gradient</span>
        <span class="c1">#       .tv_l1          total violation of all constraints at x</span>
        <span class="c1">#       .tv_l1_grad     its gradient</span>
        <span class="c1">#       PENALTY FUNCTION VALUES</span>
        <span class="c1">#       .p              penalty function value at x</span>
        <span class="c1">#       .p_grad         penalty function gradient at x</span>
        <span class="c1">#       .mu             current value of the penalty parameter</span>
        <span class="c1">#       .feasible_to_tol logical indicating whether x is feasible</span>
        <span class="c1">#   d                   search direction</span>
        <span class="c1">#   get_BFGS_state_fn   function handle to get the (L)BFGS state data</span>
        <span class="c1">#                       FULL MEMORY:</span>
        <span class="c1">#                       - returns BFGS inverse Hessian approximation</span>
        <span class="c1">#                       LIMITED MEMORY:</span>
        <span class="c1">#                       - returns a struct with current L-BFGS state:</span>
        <span class="c1">#                           .S          matrix of the BFGS s vectors</span>
        <span class="c1">#                           .Y          matrix of the BFGS y vectors</span>
        <span class="c1">#                           .rho        row vector of the 1/sty values</span>
        <span class="c1">#                           .gamma      H0 scaling factor</span>
        <span class="c1">#   H_regularized       regularized version of H</span>
        <span class="c1">#                       [] if no regularization was applied to H</span>
        <span class="c1">#   fn_evals            number of function evaluations incurred during</span>
        <span class="c1">#                       this iteration</span>
        <span class="c1">#   alpha               size of accepted size</span>
        <span class="c1">#   n_gradients         number of previous gradients used for computing</span>
        <span class="c1">#                       the termination QP</span>
        <span class="c1">#   stat_vec            stationarity measure vector</span>
        <span class="c1">#   stat_val            approximate value of stationarity:</span>
        <span class="c1">#                           norm(stat_vec)</span>
        <span class="c1">#                       gradients (result of termination QP)</span>
        <span class="c1">#   fallback_level      number of strategy needed for a successful step</span>
        <span class="c1">#                       to be taken.  See bfgssqpOptionsAdvanced.</span>
        <span class="c1">#</span>
        <span class="c1"># OUTPUT ARGUMENT</span>
        <span class="c1">#   halt                set this to true if you wish optimization to</span>
        <span class="c1">#                       be halted at the current iterate.  This can be</span>
        <span class="c1">#                       used to create a custom termination condition,</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span>

<span class="n">mHLF_obj</span> <span class="o">=</span> <span class="n">HaltLog</span><span class="p">()</span>
<span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span> <span class="o">=</span> <span class="n">mHLF_obj</span><span class="o">.</span><span class="n">makeHaltLogFunctions</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">maxit</span><span class="p">)</span>

<span class="c1">#  Set PyGRANSO&#39;s logging function in opts</span>
<span class="n">opts</span><span class="o">.</span><span class="n">halt_log_fn</span> <span class="o">=</span> <span class="n">halt_log_fn</span>

<span class="c1"># Main algorithm with logging enabled.</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>

<span class="c1"># GET THE HISTORY OF ITERATES</span>
<span class="c1"># Even if an error is thrown, the log generated until the error can be</span>
<span class="c1"># obtained by calling get_log_fn()</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">get_log_fn</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║
Version 1.1.0                                                                                                    ║
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  6.29553136148 ║  6.29553136148 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 10.15346   ║
   1 ║ 1.000000 │  2.90576271530 ║  2.90576271530 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 9.133987   ║
   2 ║ 1.000000 │  2.72445470578 ║  2.72445470578 ║ 0.000000 │   -  ║ S  │     5 │ 0.187500 ║     1 │ 1.505568   ║
   3 ║ 1.000000 │  1.91106559885 ║  1.91106559885 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.342866   ║
   4 ║ 1.000000 │  1.76433451683 ║  1.76433451683 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.606845   ║
   5 ║ 1.000000 │  1.62644975884 ║  1.62644975884 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.239095   ║
   6 ║ 1.000000 │  1.59432528916 ║  1.59432528916 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.029342   ║
   7 ║ 1.000000 │  1.44781333828 ║  1.44781333828 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.164896   ║
   8 ║ 1.000000 │  1.28221253489 ║  1.28221253489 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.035149   ║
   9 ║ 1.000000 │  1.00569562802 ║  1.00569562802 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.107021   ║
  10 ║ 1.000000 │  0.95741125610 ║  0.95741125610 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.207132   ║
  11 ║ 1.000000 │  0.75212217129 ║  0.75212217129 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.019201   ║
  12 ║ 1.000000 │  0.65908188492 ║  0.65908188492 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.233608   ║
  13 ║ 1.000000 │  0.63676908867 ║  0.63676908867 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.135931   ║
  14 ║ 1.000000 │  0.54778399295 ║  0.54778399295 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018091   ║
  15 ║ 1.000000 │  0.54025558349 ║  0.54025558349 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.184179   ║
  16 ║ 1.000000 │  0.48921486903 ║  0.48921486903 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.017499   ║
  17 ║ 1.000000 │  0.43898992011 ║  0.43898992011 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.011960   ║
  18 ║ 1.000000 │  0.31282681320 ║  0.31282681320 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.044037   ║
  19 ║ 1.000000 │  0.30613156409 ║  0.30613156409 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.089220   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 1.000000 │  0.26840442151 ║  0.26840442151 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.047436   ║
  21 ║ 1.000000 │  0.25479741711 ║  0.25479741711 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004499   ║
  22 ║ 1.000000 │  0.24141733319 ║  0.24141733319 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.157455   ║
  23 ║ 1.000000 │  0.23945738203 ║  0.23945738203 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.010527   ║
  24 ║ 1.000000 │  0.22236287080 ║  0.22236287080 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 7.13e-04   ║
  25 ║ 1.000000 │  0.19890710387 ║  0.19890710387 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.033162   ║
  26 ║ 1.000000 │  0.15480732775 ║  0.15480732775 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.133421   ║
  27 ║ 1.000000 │  0.14435953282 ║  0.14435953282 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.028799   ║
  28 ║ 1.000000 │  0.13531228983 ║  0.13531228983 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.041209   ║
  29 ║ 1.000000 │  0.12328030171 ║  0.12328030171 ║ 0.000000 │   -  ║ S  │     4 │ 3.000000 ║     1 │ 0.065059   ║
  30 ║ 1.000000 │  0.10917604522 ║  0.10917604522 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.010049   ║
  31 ║ 1.000000 │  0.10784993933 ║  0.08789680307 ║ 0.012901 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.013712   ║
  32 ║ 1.000000 │  0.10534090310 ║  0.08886444452 ║ 0.011423 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.011812   ║
  33 ║ 1.000000 │  0.09312258203 ║  0.09312258203 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.005429   ║
  34 ║ 1.000000 │  0.08893012564 ║  0.08893012564 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003905   ║
  35 ║ 1.000000 │  0.08781304550 ║  0.08781304550 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.002984   ║
  36 ║ 1.000000 │  0.08654967414 ║  0.08654967414 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001809   ║
  37 ║ 1.000000 │  0.08587399644 ║  0.08586809225 ║ 5.90e-06 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.61e-05   ║
  38 ║ 1.000000 │  0.08584862807 ║  0.08584862807 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 2.51e-05   ║
  39 ║ 1.000000 │  0.08583616120 ║  0.08583616120 ║ 0.000000 │   -  ║ S  │     5 │ 0.312500 ║     1 │ 1.19e-04   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 1.000000 │  0.08581483696 ║  0.08581483696 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 2.75e-06   ║
  41 ║ 1.000000 │  0.08579073277 ║  0.08579024691 ║ 4.86e-07 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.08e-06   ║
  42 ║ 0.531441 │  0.04559284212 ║  0.08579020654 ║ 4.09e-07 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.72e-05   ║
  43 ║ 0.531441 │  0.04559216588 ║  0.08578932096 ║ 2.03e-07 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.76e-04   ║
  44 ║ 0.531441 │  0.04559183931 ║  0.08578908911 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 5.74e-06   ║
  45 ║ 0.531441 │  0.04559169946 ║  0.08578882596 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.04e-06   ║
  46 ║ 0.531441 │  0.04559100681 ║  0.08578752262 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 2.20e-06   ║
  47 ║ 0.531441 │  0.04559047332 ║  0.08578651876 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.52e-06   ║
  48 ║ 0.185302 │  0.01589641330 ║  0.08578650355 ║ 9.94e-10 │   -  ║ S  │    12 │ 0.007324 ║     1 │ 2.28e-06   ║
  49 ║ 0.185302 │  0.01589641025 ║  0.08578645124 ║ 3.82e-09 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 9.42e-09   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578645124 ║ 3.82e-09 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578638898 ║ 5.56e-07 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578650457 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              49                                                                                      ║
Function evaluations:    109                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[6.295531361480611, 2.90576271529587, 2.724454705783729]
[tensor([[ 0.5662],
        [-0.4429]], dtype=torch.float64), tensor([[-0.4577],
        [ 0.3071]], dtype=torch.float64), tensor([[-0.5532],
        [ 0.2671]], dtype=torch.float64)]
</pre></div></div>
</div>
</section>
<section id="Advanced-Tutorial:-Restart-PyGRANSO-in-Limited-Memory-Mode">
<h2>Advanced Tutorial: Restart PyGRANSO in Limited Memory Mode<a class="headerlink" href="#Advanced-Tutorial:-Restart-PyGRANSO-in-Limited-Memory-Mode" title="Permalink to this headline">¶</a></h2>
<p>(Note that this example problem only has two variables!)</p>
<p>If PyGRANSO was running in limited-memory mode, that is, if opts.limited_mem_size &gt; 0, then PyGRANSO’s restart procedure is slightly different, as soln.H_final will instead contain the most current L-BFGS state, not a full inverse Hessian approximation.</p>
<p>Instead, do the following: 1) If you set a specific H0, you will need to set opts.H0 to whatever you used previously. By default, PyGRANSO uses the identity for H0.</p>
<ol class="arabic simple" start="2">
<li><p>Warm-start GRANSO with the most recent L-BFGS data by setting: opts.limited_mem_warm_start = soln.H_final;</p></li>
</ol>
<p>NOTE: how to set opts.scaleH0 so that PyGRANSO will be restarted as if it had never terminated depends on the previously used values of opts.scaleH0 and opts.limited_mem_fixed_scaling.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>


<span class="c1"># By default, PyGRANSO uses full-memory BFGS updating.  For nonsmooth</span>
<span class="c1"># problems, full-memory BFGS is generally recommended.  However, if</span>
<span class="c1"># this is not feasible, one may optionally enable limited-memory BFGS</span>
<span class="c1"># updating by setting opts.limited_mem_size to a positive integer</span>
<span class="c1"># (significantly) less than the number of variables.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    |
Version 1.1.0                                                                                                    |
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
Limited-memory mode enabled with size = 1.                                                                       |
NOTE: limited-memory mode is generally NOT                                                                       |
recommended for nonsmooth problems.                                                                              |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   4 | 12.15767 |  262.610250639 |  20.8774186596 | 8.789579 |   -  | S  |     2 | 2.000000 |     1 | 0.604009   |
   6 | 4.239116 |  57.9458175917 |  11.5708792009 | 8.895520 |   -  | S  |     3 | 0.750000 |     1 | 0.165224   |
   8 | 1.642320 |  26.2056730861 |  10.5532019880 | 8.873935 |   -  | S  |     1 | 1.000000 |     1 | 0.027766   |
  10 | 1.642320 |  25.9163909350 |  10.4174724535 | 8.807564 |   -  | S  |     2 | 2.000000 |     1 | 0.021455   |
==================================================================================================================
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
Optimization results:                                                                                            |
==================================================================================================================
   F |          |                |  10.4174724535 | 8.807564 |   -  |    |       |          |       |            |
  MF |          |                |  75.6886238113 | 8.192103 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    29                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Restart</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_warm_start</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># In contrast to full-memory BFGS updating, limited-memory BFGS</span>
<span class="c1"># permits that H0 can be scaled on every iteration.  By default,</span>
<span class="c1"># PyGRANSO will reuse the scaling parameter that is calculated on the</span>
<span class="c1"># very first iteration for all subsequent iterations as well.  Set</span>
<span class="c1"># this option to false to force PyGRANSO to calculate a new scaling</span>
<span class="c1"># parameter on every iteration.  Note that opts.scaleH0 has no effect</span>
<span class="c1"># when opts.limited_mem_fixed_scaling is set to true.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_fixed_scaling</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">combinedFunction</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">objEvalFunction</span> <span class="o">=</span> <span class="n">obj_eval_fn</span><span class="p">,</span><span class="n">var_dim_map</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span> <span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║
Version 1.1.0                                                                                                    ║
MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
<span class="ansi-yellow-fg">Limited-memory mode enabled with size = 1.                                                                      </span> ║
<span class="ansi-yellow-fg">NOTE: limited-memory mode is generally NOT                                                                      </span> ║
<span class="ansi-yellow-fg">recommended for nonsmooth problems.                                                                             </span> ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.642320 │  25.9163909350 ║  10.4174724535 ║ 8.807564 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.142170   ║
   2 ║ 1.642320 │  13.8166377151 ║  6.50513006006 ║ 3.133130 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.836719   ║
   4 ║ 1.642320 │  6.43974928744 ║  3.92112865088 ║ 1.56e-13 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 3.895211   ║
   6 ║ 1.642320 │  4.83427546820 ║  2.94356429086 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.051608   ║
   8 ║ 1.642320 │  4.65430930433 ║  2.83398386314 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018191   ║
  10 ║ 1.642320 │  3.93919956761 ║  2.39855739667 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.007872   ║
  12 ║ 1.642320 │  3.11104049392 ║  1.89429579791 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.063040   ║
  14 ║ 1.642320 │  2.65451447016 ║  1.61631956129 ║ 0.000000 │   -  ║ S  │     7 │ 0.046875 ║     1 │ 0.585910   ║
  16 ║ 1.642320 │  2.32306552177 ║  1.41450208210 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.127928   ║
  18 ║ 1.642320 │  2.07124172668 ║  1.26116792982 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018703   ║
  20 ║ 1.642320 │  1.90787289453 ║  1.16169352797 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.021251   ║
  22 ║ 1.642320 │  1.60077935146 ║  0.97470592388 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.037526   ║
  24 ║ 1.642320 │  1.37747264154 ║  0.83873567113 ║ 0.000000 │   -  ║ S  │     3 │ 0.750000 ║     1 │ 0.208555   ║
  26 ║ 1.642320 │  1.21777481377 ║  0.74149652408 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.033868   ║
  28 ║ 1.642320 │  1.01253483314 ║  0.61652700548 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.002344   ║
  30 ║ 1.642320 │  0.84593039090 ║  0.51508245808 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.031023   ║
  32 ║ 1.642320 │  0.72210531062 ║  0.43968603373 ║ 0.000000 │   -  ║ S  │     4 │ 0.375000 ║     1 │ 0.165331   ║
  34 ║ 1.642320 │  0.68391383067 ║  0.41643144733 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.010301   ║
  36 ║ 1.642320 │  0.62489138662 ║  0.38049299909 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018075   ║
  38 ║ 1.642320 │  0.54510979410 ║  0.33191441718 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.533453   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 1.642320 │  0.38201168372 ║  0.23260485636 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.005206   ║
  42 ║ 1.642320 │  0.33958127823 ║  0.20676921103 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.112707   ║
  44 ║ 1.642320 │  0.29638151827 ║  0.18046510990 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.058435   ║
  46 ║ 1.642320 │  0.19928113299 ║  0.12134120837 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.003281   ║
  48 ║ 1.642320 │  0.17678412761 ║  0.10764290298 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.003585   ║
  50 ║ 1.642320 │  0.17212181661 ║  0.10480404693 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001687   ║
  52 ║ 1.077526 │  0.09728310961 ║  0.09028373935 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 0.053275   ║
  54 ║ 1.077526 │  0.09371789297 ║  0.08697503457 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 2.51e-04   ║
  56 ║ 1.077526 │  0.09247825967 ║  0.08582459098 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 6.80e-04   ║
  58 ║ 1.077526 │  0.09244672381 ║  0.08579452533 ║ 8.61e-07 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.87e-06   ║
  60 ║ 0.785517 │  0.06738725671 ║  0.08578717027 ║ 0.000000 │   -  ║ S  │     8 │ 0.007812 ║     1 │ 2.07e-04   ║
  62 ║ 0.785517 │  0.06738676049 ║  0.08578653005 ║ 6.69e-09 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.01e-09   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578653005 ║ 6.69e-09 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578653005 ║ 6.69e-09 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578698564 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              62                                                                                      ║
Function evaluations:    168                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
</section>
</section>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">Examples</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="2.demo_SpectralRadiusOpt.html">Spectral Radius Optimization</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Buyun Liang.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.2.0.
    </div>
  </body>
</html>